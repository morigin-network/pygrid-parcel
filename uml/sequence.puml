@startuml DeML Sequence

' TODO: @Thomas
' draw sequence diagram to illustrate the work inside PyGrid in details,
' include at least the following:
' PyGrid, Parcel, Parcel jobs
' Make reference to code file and function as appropriate
skinparam maxMessageSize 150
participant "Data\nScientist" as ds  
participant "Data owner" as do
participant PyGrid as pygrid
participant "Parcel\nRuntime" as parcel
database "Parcel\nDocuments" as padb



== Hosting a New Model ==
ds -> pygrid: Connect Request (WebSocket)
pygrid -> ds: Accept Connection 
ds -> pygrid: host_federated_training request (parameters: train and inference model, training_plan ,averaging_plan, client_config, server_config)
note left: training model is serialized with pysyft's own library,\ninference model is saved as plaintext source code\n(self-implemented by Thomas)\nand training_plan/averaging_plan are functions\n which are serialized with the @make_plan decorator.
pygrid -> pygrid: Create new process(with a new unique process id), Start a new cycle, then save everything to database.
note left: function host_federated_training in events/model_centric/fl_events.py
== Cycle Request ==
do -> pygrid: Connect request (Websocket, Parameters: model_name and version, auth_token)
pygrid -> pygrid: Verify auth_token with respect to the model
note left: function verify_token in core/model_centric/auth/federated.py
pygrid -> pygrid: Create and save worker_id
note left: function assign_worker_id in events/model_centric/fl_events.py
pygrid -> do: Accept Connection (return worker_id)
do -> pygrid: Cycle request (Parameters: worker_id, model, version, download and upload times)
pygrid -> pygrid: Perform speed test if necessary, check last participation and compare against config
note left: function cycle_request in events/model_centric/fl_events.py
pygrid -> do: (If accept) request_key, model_id, training_plan_id
do -> pygrid: get_model request (Parameters: worker_id, request_key, model_id)
pygrid -> do: model parameters
do -> pygrid: get_plan request (Parameters: worker_id, request_key, training_plan_id)
pygrid -> do: training plan (a serialized function)
do -> do: Do the training locally 
do -> do: serialize new parameters to string, then further b64encode it
do -> padb: save parameter to parcel
padb -> do: Document id
do -> pygrid: report request (Parameters: worker_id, request_key, document id)
== Averaging ==
note over pygrid, padb: Everything here is in core/model_centric/cycles/cycle_manager.py and send_avgrequest.py
alt number of diff > threshold in config 
    pygrid -> pygrid: Retrieve document ids, averaging plan, latest model parameters from db
    pygrid -> padb: Save averaging plan and parameters to parcel
    padb -> pygrid: Document ids
    alt current_cycle is not final
        pygrid -> parcel: Compute Job request (parameters: all document ids and their mount path, docker image for mid-averaging)
        parcel -> padb: output averaged weights
        parcel -> pygrid: job output document ids
        pygrid -> padb: request downloading averaged weights (Parameters: document ids)
        padb -> pygrid: averaged weights
        pygrid -> pygrid: Update weights on db
    else current_cycle is final
        pygrid -> pygrid: Retrieve inference model from db
        pygrid -> padb: Save inference model to parcel
        padb -> pygrid: Document id
        pygrid -> parcel: Compute Job request (parameters: all document ids and their mount path, docker image for final-averaging)
        parcel -> padb: output two encrypted model weight state_dicts with owners set as SMPC workers
        padb -> pygrid: job output document ids
    end
end
@enduml
